{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a9b33d70",
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import scipy.stats as st\n",
                "import matplotlib.pyplot as plt\n",
                "from scipy.optimize import minimize\n",
                "from IPython.display import display, HTML\n",
                "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b5bb415e",
            "metadata": {},
            "source": [
                "$$ P(\\textrm{hypothesis} | \\textrm{data}, I) = \\dfrac{P(\\textrm{data} | \\textrm{hypothesis}, I) P(\\textrm{hypothesis} | I)}{P(\\textrm{data} | I)} $$"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f8c17d8b",
            "metadata": {},
            "source": [
                "# 1. Fitting a line\n",
                "\n",
                "In astronomy, a lot of information about the physical and emission properties of astronomical objects is accessed through spectroscopic measurements, i.e., the emission intensity as a function of wavelength/frequency. Interesting spectral features are emission or absorption lines. Naturally, the lines are not... lines, but narrow peaks! A true line is impossible due to quantum effects, but in addition, local/extended effects tend to \"broaden\" or alter the shape of spectal lines (e.g., thermal doppler, pressure, rotation of object, \n",
                "\n",
                "$$ y(x) = \\dfrac{A}{1 + \\left(\\dfrac{x - x_0}{w}\\right)^2}           \\qquad \\text{(Lorentzian or Cauchy model)}\n",
                "$$\n",
                "\n",
                "$$ y(x) = A \\exp{\\left[-\\frac{\\left(x - x_0\\right)^2}{2 w^2}\\right]} \\qquad \\text{(Gaussian or Normal model)}\n",
                "$$\n",
                "\n",
                "\n",
                "where \n",
                "* $A$ is the amplitude (notice that $y(x_0) = A$ in both cases), \n",
                "* $x_0$ is the location parameter (the center of the line), and\n",
                "* $w$ is the \"spread\" or width of the line.\n",
                "\n",
                "\n",
                "> Notice that here we use the word Cauchy and Gaussian to refer to non-linear models rather than distributions. Our data follows the shape of the PDFs of these distributions, not the distributions themselves!\n",
                "\n",
                "\n",
                "Now, let's assume we have measured the intensitities $y_i$ at given (unitless) wavelengths $x_i$, and that the errors $e_i$ are normally distributed with standard deviation $\\sigma$:\n",
                "\n",
                "$$ y_i = y(x_i) + \\epsilon_i, \\qquad \\epsilon_i \\sim \\text{Norm}(0, \\sigma)$$"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8e30dd12",
            "metadata": {},
            "source": [
                "## 1.1. The data from an unknown distribution"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e67d2dd8",
            "metadata": {},
            "outputs": [],
            "source": [
                "np.random.seed(2024)\n",
                "\n",
                "def make_data(x, model_dist, amplitude, location, width, error_scale=0.0):\n",
                "    \"\"\"Make a spectral line following the PDF of a given distribution.\n",
                "    \n",
                "    x           : the wavelength\n",
                "    model_dist  : the distribution of which the PDF will be used\n",
                "    amplitude   : the maximum height of the spectral line\n",
                "    location    : the center of the spectral line\n",
                "    width       : the width of the spectral line\n",
                "    error_scale : the standard deviation of the observational uncertainties\n",
                "    \n",
                "    NOTE: use default `error_scale` (0.0) to get a model instead of an observational sample.\n",
                "    \n",
                "    \"\"\"\n",
                "    distribution = model_dist(loc=location, scale=width)\n",
                "    y = distribution.pdf(x)\n",
                "    y = amplitude * y / np.max(y)\n",
                "    if error_scale > 0:\n",
                "        y = np.random.normal(y, scale=error_scale)\n",
                "    y_err = np.ones_like(y) * error_scale\n",
                "    return y, y_err\n",
                "\n",
                "\n",
                "n_data = 20\n",
                "\n",
                "# two potential distributions\n",
                "model_distributions = [st.cauchy, st.norm]\n",
                "model_distributions_names = [\"Cauchy\", \"Normal\"]\n",
                "\n",
                "# select pseudo-randomly the true distribution\n",
                "random_index = 2023 % 17 % 2\n",
                "true_model_distribution = model_distributions[random_index]\n",
                "true_model_distribution_name = model_distributions_names[random_index]\n",
                "\n",
                "# Permitted ranges for the parameters (because we processed the data and we have some intuition)\n",
                "MIN_AMPLITUDE = 0.9\n",
                "MAX_AMPLITUDE = 1.1\n",
                "MIN_LOCATION = 0.45\n",
                "MAX_LOCATION = 0.55\n",
                "MIN_WIDTH = 0.05\n",
                "MAX_WIDTH = 0.15\n",
                "\n",
                "# Select the true parameters (these are supposed to be hidden from us)\n",
                "true_amplitude = np.random.uniform(MIN_AMPLITUDE, MAX_AMPLITUDE)\n",
                "true_location = np.random.uniform(MIN_LOCATION, MAX_LOCATION)\n",
                "true_width = np.random.uniform(MIN_WIDTH, MAX_WIDTH)\n",
                "\n",
                "# Make the new data according to the true model\n",
                "x_data = np.linspace(0.0, 1.0, n_data) + np.random.uniform(-0.5/n_data, 0.5/n_data, size=n_data)\n",
                "y_data, e_data = make_data(x_data, true_model_distribution, amplitude=true_amplitude, location=true_location, width=true_width, error_scale=0.1)\n",
                "\n",
                "# Plot them!\n",
                "plt.figure()\n",
                "plt.errorbar(x_data, y_data, yerr=e_data, fmt=\"k.\", capsize=4, label=\"Data\")\n",
                "plt.legend(loc=\"upper right\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b61dfafa",
            "metadata": {},
            "source": [
                "## 1.2. Overplotting two potential models using fiducial parameters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "79e47d5a",
            "metadata": {},
            "outputs": [],
            "source": [
                "# use the midpoints of the permitted ranges of the parameters\n",
                "fiducial_amplitude = (MIN_AMPLITUDE + MAX_AMPLITUDE) / 2.0\n",
                "fiducial_location = (MIN_LOCATION + MAX_LOCATION) / 2.0\n",
                "fiducial_width = (MIN_WIDTH + MAX_WIDTH) / 2.0\n",
                "\n",
                "plt.figure()\n",
                "plt.plot(x_data, y_data, \"ks\", mfc=\"none\", label=\"Data\")\n",
                "\n",
                "for model_distribution in model_distributions:\n",
                "    x_plot = np.linspace(0, 1, 100)\n",
                "    y_plot, _ = make_data(x_plot, \n",
                "                          model_distribution,            # try this model\n",
                "                          amplitude=fiducial_amplitude,  # fiducial...\n",
                "                          location=fiducial_location,    # ...parameters...\n",
                "                          width=fiducial_width,          # ...from ranges\n",
                "                          error_scale=0.0                # the prediction does not have uncertainty\n",
                "                         )\n",
                "    plt.plot(x_plot, y_plot, label=model_distribution.name)\n",
                "\n",
                "plt.legend(loc=\"upper right\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e98fd307",
            "metadata": {},
            "source": [
                "<font size=3><u>**In-class discussion: The plotted models use fiducial values for the parameters. However to you think one fits best than the other?**</u><font>\n",
                "\n",
                "_Discuss with your teammate, then report._\n",
                "\n",
                "<details>\n",
                "<summary><b>[Spoiler]</b></summary>\n",
                "<br>\n",
                "It's purely subjective at this point!\n",
                "<br>\n",
                "    "
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0b43b5a6",
            "metadata": {},
            "source": [
                "# 1.3. Defining the prior, likelihood and posterior assuming Gaussian profile...\n",
                "\n",
                "**Reminder**: we operate in log-space (log-prior, log-likelihood, log-posterion) for numerical reasons.\n",
                "\n",
                "<div class=\"alert alert-block alert-warning\" style=\"margin-top: 20px\">\n",
                "\n",
                "**Task:**  Complete the functions. Hint: the `make_data` function can be used to get model predictions as well! \n",
                "    \n",
                "**Warning**: the function returns two things!\n",
                "</div>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bfca01d2",
            "metadata": {},
            "source": [
                "**(Reminder) From cell above:**\n",
                "```python\n",
                "# Permitted ranges for the parameters (because we processed the data and we have some intuition)\n",
                "MIN_AMPLITUDE = 0.9\n",
                "MAX_AMPLITUDE = 1.1\n",
                "MIN_LOCATION = 0.45\n",
                "MAX_LOCATION = 0.55\n",
                "MIN_WIDTH = 0.05\n",
                "MAX_WIDTH = 0.15\n",
                "\n",
                "# Our observed data\n",
                "x_data = np.linspace(0.0, 1.0, n_data) + np.random.uniform(-0.5/n_data, 0.5/n_data, size=n_data)\n",
                "y_data, e_data = make_data(x_data, true_model_distribution, amplitude=true_amplitude, location=true_location, width=true_width, error_scale=0.1)\n",
                "```\n",
                "\n",
                "**(Reminder): From MLE notebook:**\n",
                "\n",
                "Under the assumption of Gaussian uncertainties and independence of data,\n",
                "$$\n",
                "\\ln L = \\text{constant} - \\frac{1}{2} \\sum_{i=1}^{N} {\\dfrac{(y_i-f(x_i))^2}{\\sigma_i^2}} = \\text{constant} - \\frac{\\chi^2}{2}\n",
                "$$\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "037da758",
            "metadata": {},
            "outputs": [],
            "source": [
                "def ln_prior(amplitude, location, width):\n",
                "    ...\n",
                "\n",
                "def ln_likelihood_norm(amplitude, location, width):\n",
                "    ...\n",
                "\n",
                "def ln_posterior_norm(amplitude, location, width):\n",
                "    ..."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6b4a53fa",
            "metadata": {},
            "source": [
                "# 1.4. Maximizing the posterior\n",
                "\n",
                "<div class=\"alert alert-block alert-warning\" style=\"margin-top: 20px\">\n",
                "\n",
                "**Tasks:**\n",
                "1. Define the function to be minimized in order to maximize the posterior.\n",
                "2. Choose appropriate starting values for the minimization routine.\n",
                "</div>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c53b94bf",
            "metadata": {},
            "outputs": [],
            "source": [
                "def neg_ln_posterior_norm(theta):\n",
                "    amplitude, location, width = theta\n",
                "    return ...\n",
                "\n",
                "min_result_norm = minimize(neg_ln_posterior_norm, x0=[..., ..., ...], method='Nelder-Mead')\n",
                "est_amplitude, est_location, est_width = min_result_norm.x\n",
                "\n",
                "\n",
                "print(min_result_norm)\n",
                "print()\n",
                "print(\"| PARAMETER  |  ESTIMATION  |  TRUTH  |\")\n",
                "print(f\"| amplitude  | {est_amplitude:11.3f}  | {true_amplitude:6.3f}  |\")\n",
                "print(f\"| location   | {est_location:11.3f}  | {true_location:6.3f}  |\")\n",
                "print(f\"| width      | {est_width:11.3f}  | {true_width:6.3f}  |\")\n",
                "print()\n",
                "print(\"At best-fitting values...\")\n",
                "lnL_norm = ln_likelihood_norm(*min_result_norm.x)\n",
                "lnP_norm = ln_posterior_norm(*min_result_norm.x)\n",
                "print(f\"  * log-prior      : {ln_prior(*min_result_norm.x):.6f}\")\n",
                "print(f\"  * log-likelihood : {lnL_norm:.6f}\")\n",
                "print(f\"  * log-posterior  : {lnP_norm:.6f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "01e9a850",
            "metadata": {},
            "source": [
                "<font size=3><u>**In-class discussion: The fit was successful and we got parameters close to the truth. Is the Gaussian model validated?**</u><font>\n",
                "\n",
                "_Discuss with your teammate, then report._\n",
                "\n",
                "<details>\n",
                "<summary><b>[Spoiler]</b></summary>\n",
                "<br>\n",
                "As in hypothesis testing, the model is assumed to be true. The fitting process does not validate the model. The value of the log-posterior does not convey any information regarding the validity of the model.\n",
                "<br>\n",
                "    "
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0984de78",
            "metadata": {},
            "source": [
                "## 1.5. Repeating using a Cauchy profile\n",
                "\n",
                "<div class=\"alert alert-block alert-warning\" style=\"margin-top: 20px\">\n",
                "\n",
                "**Tasks:**  Do the same steps for the Cauchy profile.\n",
                "    \n",
                "1. Complete the functions.\n",
                "2. Choose appropriate starting values for the minimization routine.\n",
                "</div>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7413493a",
            "metadata": {},
            "outputs": [],
            "source": [
                "def ln_likelihood_cauchy(amplitude, location, width):\n",
                "    ...\n",
                "\n",
                "def ln_posterior_cauchy(amplitude, location, width):\n",
                "    ...\n",
                "\n",
                "def neg_ln_posterior_cauchy(theta):\n",
                "    amplitude, location, width = theta\n",
                "    return ...\n",
                "\n",
                "min_result_cauchy = minimize(neg_ln_posterior_cauchy, x0=[..., ..., ...], method='Nelder-Mead')\n",
                "est_amplitude, est_location, est_width = min_result_cauchy.x\n",
                "\n",
                "print(min_result_cauchy)\n",
                "print()\n",
                "print(\"| PARAMETER  |  ESTIMATION  |  TRUTH  |\")\n",
                "print(f\"| amplitude  | {est_amplitude:11.3f}  | {true_amplitude:6.3f}  |\")\n",
                "print(f\"| location   | {est_location:11.3f}  | {true_location:6.3f}  |\")\n",
                "print(f\"| width      | {est_width:11.3f}  | {true_width:6.3f}  |\")\n",
                "print()\n",
                "print(\"At best-fitting values...\")\n",
                "lnL_cauchy = ln_likelihood_cauchy(*min_result_cauchy.x)\n",
                "lnP_cauchy = ln_posterior_cauchy(*min_result_cauchy.x)\n",
                "print(f\"  * log-prior      : {ln_prior(*min_result_cauchy.x):.6f}\")\n",
                "print(f\"  * log-likelihood : {lnL_cauchy:.6f}\")\n",
                "print(f\"  * log-posterior  : {lnP_cauchy:.6f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7036fa27",
            "metadata": {},
            "source": [
                "<font size=3><u>**In-class discussion: What can you infer from the comparison between the resulting when assuming normal vs. Cauchy?**</u><font>\n",
                "\n",
                "_Discuss with your teammate, then report._\n",
                "\n",
                "<details>\n",
                "<summary><b>[Spoiler]</b></summary>\n",
                "<br>\n",
                "The parameters are in both cases close to the truth. Whether they are closer or not, in practice, we cannot use in real data because we don't know the truth!\n",
                "The likelihood and posterior is, however, different! Maybe we can use this?\n",
                "<br>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e8c7345c",
            "metadata": {},
            "source": [
                "# 2. Selecting models\n",
                "\n",
                "If we don't know the correct model for the data ($D$), then we have a model selection problem. We should come up with all potential models, or at least those expected from our prior experience with the data and the underlying mechanisms decribing them.\n",
                "\n",
                "In the case above we have the Normal and Cuachy model. Let's name them A and B respectively. We can compare the posteriors by taking their ratio:\n",
                "\n",
                "Posterior odds: $ \\dfrac{P(A|D)}{P(B|D)} $\n",
                "\n",
                "Using the Bayes rule we can express it in the following way:\n",
                "\n",
                "$$ \\dfrac{P(A|D)}{P(B|D)} = \\dfrac{P(D|A)P(A) / P(D)}{P(D|B)P(B) / P(D)} = \\dfrac{P(D|A)P(A)}{P(D|B)P(B)}$$\n",
                "\n",
                "## 2.1. Likelihood ratio (prior-independent)\n",
                "\n",
                "As we can see, the results depend on our prior belief on the models. In many cases, we want to be completely fair, and therefore we assign equal prior to both of them, resulting in:\n",
                "\n",
                "$$ \\dfrac{P(D|A)}{P(D|B)} $$\n",
                "\n",
                "which is also used by **frequentists** under the name **likelihood ratio statistic**:\n",
                "\n",
                "$$ \\mathrm{LR}_{AB} = \\dfrac{L_A}{L_B} = e^{l_A - l_B} $$\n",
                "\n",
                "where the $l_A$ and $l_B$ are the log-likelihoods for convenience.\n",
                "\n",
                "> The larger the likelihood ratio, the more preferred Model A is with respect to Model B\n",
                "\n",
                "\n",
                "### Connection to comparison of $\\chi^2$ values\n",
                "\n",
                "Under the assumption of Gaussian errors, then our log-likelihood is: *(some constant)* $-\\chi^2$. Therefore, if we compute the $\\chi^2$ values of the best fitting parameters for our models A and B, then the likelihood ratio is:\n",
                "\n",
                "$$ \\mathrm{LR}_{AB} = e^{l_A - l_B} = e^{-\\chi_A^2+\\chi_B^2} $$\n",
                "\n",
                "so the model with smallest $\\chi^2$ is preferred.\n",
                "\n",
                "## 2.2. Taking into account the flexibility of the models\n",
                "\n",
                "In classical statistics, we don't compare $\\chi^2$ values, but the **reduced-$\\chi^2$** which is divided by the degrees of freedom (number of data point - number of model parameters) to penalize complicated models that can fit the data easily without necessarily being the true model. In Bayesian statistics there are varous tools:\n",
                "\n",
                "### The Akaike Information Criterion\n",
                "\n",
                "If we use a model to represent the data, we lose information! There is structure/noise/etc. that we have lost! AIC measures the amount of information that is lost, **relative to another model**.\n",
                "\n",
                "A good model \"extracts\" or \"represents\" most of the information from a system, or... it maximizes its entropy! The AIC is the application of the Second Law of Thermodynamics on statistics using information theory (cf. *Shannon's information entropy*).\n",
                "\n",
                "$$\n",
                "\\text{AIC} = 2k - 2\\ln L\n",
                "$$\n",
                "\n",
                "where $k$ is the number of parameters of the model (if we had to estimate them from the data), and $L$ is the likelihood of the data according to the model.\n",
                "\n",
                "\n",
                "> The larger the AIC, the more information is lost, so the worst for our model!\n",
                "\n",
                "\n",
                "\n",
                "#### k is a penalty term\n",
                "\n",
                "Using a 100-degree polynomial or a k-nearest neighbor interpolator, we could capture all trends in the data. However, this is just shifting all the information into parameters - it's not fair to compare something like that against a linear model!\n",
                "\n",
                "### The Bayesian Information Criterion\n",
                "\n",
                "$$\n",
                "\\text{BIC} = k \\ln N - 2\\ln L\n",
                "$$\n",
                "\n",
                "where $N$ is the size of the sample used to calculate the likelihood.\n",
                "\n",
                "AIC vs. BIC: it's complicated...\n",
                "\n",
                "> As in AIC, the larger the BIC, the more information is lost, so the worst for our model!\n",
                "\n",
                "\n",
                "\n",
                "### Bayesian Factors\n",
                "\n",
                "Like the likelihood ratio, but here, the likelihoods are not that of the best fit. It takes into account all possible values for the parameters (which can be different in each model), $\\theta$!\n",
                "\n",
                "$$\n",
                "\\text{K} = \\dfrac{P(D|A)}{P(D|B)} = \\dfrac{\\int P(\\theta_A) P(D|\\theta_A, A) d\\theta} {\\int P(\\theta_B) P(D|\\theta_B, B) d\\theta}\n",
                "$$\n",
                "\n",
                "> As in the likelihood ratio, the larger the value, the better for Model A compared to Model B!\n",
                "\n",
                "\n",
                "### The Jeffreys' scale\n",
                "\n",
                "| Bayes Factor | Strength of evidence |\n",
                "| --- | --- |\n",
                "|  1 - 3.2 | Not worth more than a bare mention |\n",
                "|  3.2 - 10 | Substantial |\n",
                "|  10 - 100 | Strong |\n",
                "|  >100 | Decisive |\n",
                "\n",
                "\n",
                "## 2.3. Let's compare the AICs, BICs\n",
                "\n",
                "<div class=\"alert alert-block alert-warning\" style=\"margin-top: 20px\">\n",
                "\n",
                "**Task:**  Calculate the AICs and BICs, and decide which model *won*!\n",
                "</div>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d0d307ff",
            "metadata": {},
            "outputs": [],
            "source": [
                "AIC_norm = ...\n",
                "AIC_cauchy = ...\n",
                "\n",
                "BIC_norm = ...\n",
                "BIC_cauchy = ...\n",
                "\n",
                "print(\"AIC (norm, cauchy):\", AIC_norm, AIC_cauchy)\n",
                "print(\"BIC (norm, cauchy):\", BIC_norm, BIC_cauchy)\n",
                "print(\"Posterior ratio (norm / cauchy)  =\", np.exp(lnP_norm - lnP_cauchy))\n",
                "print(\"Posterior ratio (cauchy / norm)  =\", np.exp(lnP_cauchy - lnP_norm))\n",
                "\n",
                "print(\"And the truth is.... (drum roll)... The\", true_model_distribution_name, \"distribution!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "71e2f565",
            "metadata": {},
            "source": [
                "# 3. Helping model selection\n",
                "\n",
                "<font size=3><u>**In-class discussion: What could you change to increase the contrast between the models??**</u><font>\n",
                "\n",
                "_Discuss with your teammate, then report._\n",
                "\n",
                "<details>\n",
                "<summary><b>[Spoiler]</b></summary>\n",
                "<br>\n",
                "Since the models cannot change, data have to. Only if we get more data we can be more confident in selecting models. Increase the size of the synthetic data and try again!\n",
                "<br>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "34ab8db5",
            "metadata": {},
            "source": [
                "# 4. Computing the Bayes Factor\n",
                "\n",
                "Bayes Factors are agnostic about the location of the posterior maximum! They use the *marginal likelihood* or the *evidence*: the integral of the likelihood over all possible values of the parameters.\n",
                "\n",
                "This makes them hard to compute, especially in complex, multi-dimensional parameter spaces. Thankfully, there are techniques like **Monte Carlo integration** that can help us.\n",
                "\n",
                "Essentially, instead of integrating a function over $x$, we use the sum of uniform samples of $x$:\n",
                "\n",
                "$$ \\int\\limits_a^b f(x) dx \\approx \\frac{b-a}{N} \\sum\\limits_{i=1}^N f(x_i) $$\n",
                "\n",
                "or in $k$ dimensions, a sum over the whole volume $V$ of the multi-dimensional parameter space $\\Omega$:\n",
                "\n",
                "$$ \\int_\\Omega f(\\vec{x}) d\\vec{x} \\approx \\frac{V}{N} \\sum\\limits_{i=1}^N f(\\vec{x}_i)$$\n",
                "\n",
                "<div class=\"alert alert-block alert-warning\" style=\"margin-top: 20px\">\n",
                "\n",
                "**Tasks:**\n",
                "    \n",
                "1. Choose a sample size for the Monte Carlo calculation.\n",
                "2. Calculate the Bayes factor.\n",
                "3. Which model is preferred? Does this agree with AIC and BIC?\n",
                "</div>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2b17ca32",
            "metadata": {},
            "outputs": [],
            "source": [
                "sample_size = ...\n",
                "amp_samples = np.random.uniform(MIN_AMPLITUDE, MAX_AMPLITUDE, size=sample_size)\n",
                "loc_samples = np.random.uniform(MIN_LOCATION, MAX_LOCATION, size=sample_size)\n",
                "wid_samples = np.random.uniform(MIN_WIDTH, MAX_WIDTH, size=sample_size)\n",
                "\n",
                "# use no normalization factor (watch out for the NaNs)\n",
                "ln_norm_factor = 0.0\n",
                "print(\"Normalization factor:\", ln_norm_factor)\n",
                "\n",
                "sum_norm = 0.0\n",
                "sum_cauchy = 0.0\n",
                "\n",
                "for amp, loc, wid in zip(amp_samples, loc_samples, wid_samples):\n",
                "    sum_norm += ...\n",
                "    sum_cauchy += ...\n",
                "    \n",
                "K = sum_norm / sum_cauchy\n",
                "print(f\"K (norm / cauchy): {K:.4g}\")\n",
                "print(f\"K (cauchy / norm): {1.0/K:.4g}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b32ae9a3",
            "metadata": {},
            "source": [
                "### Warning: Numerical precision & machine $\\epsilon$ (`eps`)\n",
                "\n",
                "1. Probabilities (or their densities) can be very small numbers, especially when calculated away from the maxima. \n",
                "2. Likelihoods (and hence priors) can be even smaller if we have large datasets (because probabilities are multiplied). \n",
                "\n",
                "**Example**\n",
                "It's not unconceivable to have log-likelihood values $\\ln L_i \\approx -10000$. If we need to do operations in the linear space, e.g., $L_i \\approx e^{-10000}$ we will end up with a bunch of zeros due to the limited exponent range of floating-point numbers.\n",
                "\n",
                "**Solution**: We can use a normalization factor that brings these numbers closer to 1. ***We need to be sure that we use the same factor accross all evaluations of the likelihoods/posteriors, and all models if we perform model comparisons***. This normalization factor can be the first number we obtain in our calculations,\n",
                "$$\\large L_i = L_1 \\frac{L_i}{L_1} \\propto e^{\\ln L_i - \\ln L_1}, $$\n",
                "or perhaps the mean, or median, or minimum/maximum value we encountered (however this requires to save all values),\n",
                "$$\\large L_i \\propto e^{\\ln L_i - \\max \\{\\ln L_i\\}} $$"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7ad79e2e",
            "metadata": {},
            "source": [
                "# 5. Discussion: Bayesian vs. Frequentist\n",
                "\n",
                "<font size=3><u>**In-class discussion: What are the main differences between the two approaches? Which one we prefer in astronomy/cosmology?**</u><font>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "95409acc",
            "metadata": {},
            "source": [
                "## Connecting Bayesian Inference with Maximum Likelihood Estimation (MLE)\n",
                "\n",
                "It's insightful to connect the Bayesian framework with the Maximum Likelihood Estimation (MLE) approach we've seen earlier. Recall that in MLE, we seek to find the parameter values $\\theta_{MLE}$ that maximize the likelihood function $L(\\theta | \\text{data}) = P(\\text{data} | \\theta)$.\n",
                "\n",
                "Bayes' Theorem states:\n",
                "$$ P(\\theta | \\text{data}) = \\frac{P(\\text{data} | \\theta) P(\\theta)}{P(\\text{data})} $$\n",
                "\n",
                "If we assume a **uniform (flat) prior** for $\\theta$, $P(\\theta) = C$ (a constant), then the posterior probability becomes:\n",
                "$$ P(\\theta | \\text{data}) \\propto P(\\text{data} | \\theta) \\times C \\propto P(\\text{data} | \\theta) $$\n",
                "In this specific case (uniform prior), maximizing the posterior probability $P(\\theta | \\text{data})$ is equivalent to maximizing the likelihood $P(\\text{data} | \\theta)$. Thus, the **Maximum A Posteriori (MAP)** estimate, $\\theta_{MAP}$, coincides with the MLE estimate, $\\theta_{MLE}$.\n",
                "\n",
                "**Key Differences and Similarities:**\n",
                "\n",
                "1.  **Role of Priors**: The most significant difference is the inclusion of priors $P(\\theta)$ in Bayesian inference. MLE does not formally incorporate prior beliefs about the parameters. If the prior is not uniform, then $\\theta_{MAP}$ will generally differ from $\\theta_{MLE}$. The prior effectively pulls the MAP estimate away from the MLE estimate, towards regions of higher prior probability.\n",
                "2.  **Output**: MLE provides a point estimate for the parameters (and confidence intervals are often derived using approximations based on the likelihood function's curvature). Bayesian inference provides a full posterior probability distribution for the parameters, which describes our complete state of knowledge (and uncertainty) about them. Credible regions are derived directly from this posterior.\n",
                "3.  **Interpretation**: The interpretation of results differs. MLE is rooted in the frequentist idea of how often data like ours would be observed if a parameter had a certain value. Bayesian inference provides a probabilistic statement about the parameter itself, given the observed data and prior beliefs.\n",
                "4.  **Small Data Sets**: With small datasets, the choice of prior can have a more noticeable impact on the posterior. As the amount of data increases, the likelihood term $P(\\text{data} | \\theta)$ tends to dominate the prior, and Bayesian results often converge towards MLE results (assuming the prior is not overly restrictive or zero in the region of high likelihood). This is known as the data overwhelming the prior.\n",
                "5.  **Marginalization**: Bayesian methods naturally handle nuisance parameters (parameters that are part of the model but not of primary interest) by integrating them out of the posterior (marginalization). While MLE can sometimes be adapted for this, it's a more direct and principled process in Bayesian inference.\n",
                "\n",
                "**Example: MLE for a Gaussian vs. Bayesian with Uniform Prior**\n",
                "\n",
                "Let's revisit the example of estimating the mean $\\mu$ of a Gaussian distribution from $N$ measurements $\\{x_i\\}$, assuming a known $\\sigma$.\n",
                "The likelihood is:\n",
                "$$ L(\\mu | \\{x_i\\}, \\sigma) = P(\\{x_i\\} | \\mu, \\sigma) = \\prod_{i=1}^N \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(x_i-\\mu)^2}{2\\sigma^2}\\right) $$\n",
                "Maximizing this likelihood (or its logarithm) gives the MLE estimate $\\mu_{MLE} = \\bar{x} = \\frac{1}{N}\\sum x_i$.\n",
                "\n",
                "Now, consider a Bayesian approach with a uniform prior for $\\mu$, $P(\\mu|I) \\propto C$.\n",
                "The posterior is $P(\\mu | \\{x_i\\}, \\sigma, I) \\propto P(\\{x_i\\} | \\mu, \\sigma, I)$.\n",
                "The value of $\\mu$ that maximizes this posterior (the MAP estimate) will be the same as $\\mu_{MLE}$, i.e., $\\bar{x}$.\n",
                "However, the Bayesian approach also gives us a full posterior distribution for $\\mu$. If we had used an informative Gaussian prior for $\\mu$, the MAP estimate would be a precision-weighted average of the prior mean and the sample mean, and would differ from the MLE.\n",
                "\n",
                "Let's illustrate with a simple code example where we have a few data points and compare the likelihood (which is proportional to the posterior with a flat prior) with a posterior resulting from an informative Gaussian prior."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7b048ec3",
            "metadata": {},
            "outputs": [],
            "source": [
                "# MLE vs Bayesian Example\n",
                "np.random.seed(42)\n",
                "data_points = np.array([1.5, 2.0, 2.5, 3.0, 3.5]) # Our observed data\n",
                "sigma_known = 1.0 # Assume known standard deviation of measurements\n",
                "N_data = len(data_points)\n",
                "\n",
                "mu_mle = np.mean(data_points)\n",
                "print(f\"MLE estimate for μ: {mu_mle:.2f}\")\n",
                "\n",
                "# Define the likelihood function (proportional to posterior with flat prior)\n",
                "def log_likelihood_gaussian(mu, data, sigma):\n",
                "    return -N_data/2 * np.log(2 * np.pi * sigma**2) - np.sum((data - mu)**2) / (2 * sigma**2)\n",
                "\n",
                "mu_values = np.linspace(0, 6, 300)\n",
                "log_L_values = np.array([log_likelihood_gaussian(mu, data_points, sigma_known) for mu in mu_values])\n",
                "L_values = np.exp(log_L_values - np.max(log_L_values)) # Normalize for plotting\n",
                "\n",
                "# Define an informative Gaussian prior: P(μ|I) ~ N(μ_prior, σ_prior^2)\n",
                "mu_prior, sigma_prior = 4.0, 0.5\n",
                "prior_pdf_values = st.norm.pdf(mu_values, loc=mu_prior, scale=sigma_prior)\n",
                "\n",
                "# Calculate the posterior: P(μ|data) ∝ Likelihood * Prior\n",
                "# (For Gaussian likelihood and Gaussian prior, the posterior is also Gaussian)\n",
                "# Effective data precision for the mean\n",
                "data_precision = N_data / sigma_known**2\n",
                "prior_precision = 1 / sigma_prior**2\n",
                "\n",
                "posterior_variance = 1 / (data_precision + prior_precision)\n",
                "posterior_mean = posterior_variance * (data_precision * mu_mle + prior_precision * mu_prior)\n",
                "posterior_pdf_values = st.norm.pdf(mu_values, loc=posterior_mean, scale=np.sqrt(posterior_variance))\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.plot(mu_values, L_values / np.trapz(L_values, mu_values), label='Likelihood (∝ Posterior with flat prior)', linestyle='--')\n",
                "plt.plot(mu_values, prior_pdf_values / np.trapz(prior_pdf_values, mu_values), label=f'Informative Prior: N({mu_prior}, {sigma_prior**2})', linestyle=':')\n",
                "plt.plot(mu_values, posterior_pdf_values / np.trapz(posterior_pdf_values, mu_values), label=f'Posterior with Informative Prior: N({posterior_mean:.2f}, {posterior_variance:.2f})', color='red')\n",
                "plt.axvline(mu_mle, color='blue', linestyle='-.', label=f'MLE estimate μ_MLE = {mu_mle:.2f}')\n",
                "plt.axvline(posterior_mean, color='darkred', linestyle='-.', label=f'MAP estimate (with informative prior) μ_MAP = {posterior_mean:.2f}')\n",
                "plt.title('Likelihood, Prior, and Posterior for Gaussian Mean μ')\n",
                "plt.xlabel('Parameter value μ')\n",
                "plt.ylabel('Normalized Probability Density')\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.show()\n",
                "\n",
                "print(f\"Posterior mean (MAP with Gaussian prior): {posterior_mean:.2f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a69ae85b",
            "metadata": {},
            "source": [
                "## Bayesian Credible Regions (or Intervals)\n",
                "\n",
                "Once we have the posterior probability distribution $P(\\text{hypothesis} | \\text{data}, I)$, which tells us the probability of different parameter values (our hypothesis) given the data, we often want to summarize it.\n",
                "\n",
                "*   **Point Estimates**: We might report the **Maximum A Posteriori (MAP)** value (the mode of the posterior), the **mean**, or the **median** of the posterior distribution as a single best guess for our parameter.\n",
                "\n",
                "*   **Credible Regions**: More comprehensively, we define a **credible region** (or credible interval for a single parameter) that contains a certain amount of the posterior probability, for example, 90% or 95%.\n",
                "    *   A $X\\%$ credible region is an interval $[a, b]$ such that $\\int_a^b P(\\text{parameter} | \\text{data}, I) d(\\text{parameter}) = X/100$.\n",
                "    *   **Interpretation**: A $X\\%$ credible region means there is a $X\\%$ probability that the true value of the parameter lies within that interval, given our data and model. This is a direct statement about the parameter's location.\n",
                "\n",
                "**Crucial Distinction: Credible Regions vs. Frequentist Confidence Intervals**\n",
                "\n",
                "This interpretation is fundamentally different from a frequentist confidence interval:\n",
                "*   A **Bayesian $X\\%$ credible region** is a statement about the probability of the parameter's value, given the observed data. The interval is fixed, and we assign a probability to the parameter being in it.\n",
                "*   A **frequentist $X\\%$ confidence interval** is constructed such that if we were to repeat the experiment many times, $X\\%$ of such *calculated intervals* would contain the true, fixed parameter value. It's a statement about the long-run performance of the interval construction procedure, not directly about the probability of the parameter lying in a *specific, calculated* interval from our single dataset.\n",
                "For scientists interpreting a single experiment, the Bayesian credible region often aligns more intuitively with the question: \\\"How likely is the parameter to be in this range, based on my data?\\\"\n",
                "\n",
                "**Types of Credible Regions**\n",
                "\n",
                "Credible regions are not unique. For a given probability level (e.g., 90%), common ways to define the interval include:\n",
                "*   **Equal-Tailed Interval (or Central Credible Interval)**: This interval is defined by cutting off $(100-X)/2\\%$ of the probability from each tail of the posterior distribution. For example, a 90% equal-tailed interval excludes 5% from the lower tail and 5% from the upper tail. This is often easy to compute.\n",
                "*   **Highest Posterior Density (HPD) Interval**: This interval is constructed such that all points inside it have a higher posterior probability density than any point outside it. It is the shortest possible interval containing $X\\%$ of the probability. While conceptually useful, it can be more complex to calculate, especially for asymmetric or multimodal posteriors.\n",
                "\n",
                "For simplicity in our example, we will focus on the equal-tailed interval."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8237489f",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simple Example: Illustrating a Credible Interval\n",
                "# Assume we have obtained a posterior distribution for a parameter θ.\n",
                "# For this illustration, let's use a Gamma distribution as our posterior.\n",
                "# P(θ|data, I) ~ Gamma(shape=a, scale=b)\n",
                "\n",
                "shape_param = 5.0  # Example shape parameter for the Gamma posterior\n",
                "scale_param = 1.0  # Example scale parameter for the Gamma posterior\n",
                "# For scipy.stats.gamma, 'a' is the shape parameter. 'scale' is the scale parameter.\n",
                "posterior_dist = st.gamma(a=shape_param, scale=scale_param)\n",
                "\n",
                "# Values for plotting the PDF\n",
                "# Plot from near 0 up to a high percentile to see the shape\n",
                "theta_values = np.linspace(posterior_dist.ppf(0.001), posterior_dist.ppf(0.999), 300)\n",
                "posterior_pdf_values = posterior_dist.pdf(theta_values)\n",
                "\n",
                "plt.figure(figsize=(9, 4))\n",
                "plt.plot(theta_values, posterior_pdf_values, label=f'Posterior P(θ|data) ~ Gamma(shape={shape_param:.1f}, scale={scale_param:.1f})', color='darkorange')\n",
                "\n",
                "# Point Estimate: Mean of the posterior\n",
                "mean_theta = posterior_dist.mean()\n",
                "plt.axvline(mean_theta, color='red', linestyle='--', label=f'Mean θ ≈ {mean_theta:.2f}')\n",
                "\n",
                "# 90% Equal-Tailed Credible Interval\n",
                "confidence_level = 0.90\n",
                "lower_bound, upper_bound = posterior_dist.interval(confidence_level)\n",
                "plt.fill_between(theta_values, posterior_pdf_values,\n",
                "                 where=(theta_values >= lower_bound) & (theta_values <= upper_bound),\n",
                "                 color='moccasin', alpha=0.8,\n",
                "                 label=f'{confidence_level*100:.0f}% Equal-Tailed CI [{lower_bound:.2f}, {upper_bound:.2f}]')\n",
                "\n",
                "plt.title('Posterior Distribution (Gamma Example) with Point Estimate and 90% Credible Interval')\n",
                "plt.xlabel('Parameter value θ')\n",
                "plt.ylabel('Probability Density')\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.ylim(bottom=0)\n",
                "plt.show()\n",
                "\n",
                "print(f\"Assumed Posterior Distribution: Gamma(shape={shape_param}, scale={scale_param})\")\n",
                "print(f\"Mean of the posterior (point estimate): {mean_theta:.2f}\")\n",
                "print(f\"{confidence_level*100:.0f}% Equal-Tailed Credible Interval for θ: [{lower_bound:.2f}, {upper_bound:.2f}]\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0f204a3a",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "markdown",
            "id": "ba675243",
            "metadata": {},
            "source": [
                "<table><tr>\n",
                "<td> <img src=\"images/frequentists_vs_bayesians.png\" style=\"height:700px;\"/> </td>\n",
                "<td> <img src=\"images/modified_bayes_theorem.png\" style=\"height: 300px;\"/> </td>\n",
                "</tr></table>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a8779f8d",
            "metadata": {},
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python (AstroStat24)",
            "language": "python",
            "name": "astrostat24"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.16"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
